#!/usr/bin/env python3
"""
æµ‹è¯•è¿è¡Œè„šæœ¬
æä¾›å„ç§æµ‹è¯•è¿è¡Œé€‰é¡¹å’ŒæŠ¥å‘Šç”Ÿæˆ
"""

import os
import sys
import argparse
import subprocess
from pathlib import Path
from typing import List, Optional

def run_command(cmd: List[str], description: str) -> bool:
    """è¿è¡Œå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
    print(f"\n{'='*60}")
    print(f"è¿è¡Œ: {description}")
    print(f"å‘½ä»¤: {' '.join(cmd)}")
    print(f"{'='*60}")

    try:
        result = subprocess.run(cmd, check=True, capture_output=False)
        print(f"âœ… {description} - æˆåŠŸ")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ {description} - å¤±è´¥ (é€€å‡ºç : {e.returncode})")
        return False

def run_unit_tests(verbose: bool = False, coverage: bool = True) -> bool:
    """è¿è¡Œå•å…ƒæµ‹è¯•"""
    cmd = ["python", "-m", "pytest", "tests/unit", "-m", "unit"]

    if verbose:
        cmd.append("-v")

    if coverage:
        cmd.extend([
            "--cov=backend",
            "--cov-report=html:htmlcov/unit",
            "--cov-report=term-missing",
            "--cov-report=xml:coverage-unit.xml",
            "--cov-fail-under=80"
        ])

    return run_command(cmd, "å•å…ƒæµ‹è¯•")

def run_integration_tests(verbose: bool = False) -> bool:
    """è¿è¡Œé›†æˆæµ‹è¯•"""
    cmd = ["python", "-m", "pytest", "tests/integration", "-m", "integration"]

    if verbose:
        cmd.append("-v")

    return run_command(cmd, "é›†æˆæµ‹è¯•")

def run_e2e_tests(verbose: bool = False) -> bool:
    """è¿è¡Œç«¯åˆ°ç«¯æµ‹è¯•"""
    cmd = ["python", "-m", "pytest", "tests/e2e", "-m", "e2e"]

    if verbose:
        cmd.append("-v")

    return run_command(cmd, "ç«¯åˆ°ç«¯æµ‹è¯•")

def run_performance_tests(verbose: bool = False) -> bool:
    """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
    cmd = ["python", "-m", "pytest", "tests/performance", "-m", "performance"]

    if verbose:
        cmd.append("-v")

    return run_command(cmd, "æ€§èƒ½æµ‹è¯•")

def run_ai_tests(verbose: bool = False) -> bool:
    """è¿è¡ŒAIç›¸å…³æµ‹è¯•"""
    cmd = ["python", "-m", "pytest", "-m", "ai"]

    if verbose:
        cmd.append("-v")

    return run_command(cmd, "AIåŠŸèƒ½æµ‹è¯•")

def run_api_tests(verbose: bool = False) -> bool:
    """è¿è¡ŒAPIæµ‹è¯•"""
    cmd = ["python", "-m", "pytest", "-m", "api"]

    if verbose:
        cmd.append("-v")

    return run_command(cmd, "APIæ¥å£æµ‹è¯•")

def run_all_tests(verbose: bool = False, coverage: bool = True) -> bool:
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\nğŸš€ å¼€å§‹è¿è¡Œæ‰€æœ‰æµ‹è¯•...")

    test_functions = [
        (run_unit_tests, "å•å…ƒæµ‹è¯•"),
        (run_integration_tests, "é›†æˆæµ‹è¯•"),
        (run_ai_tests, "AIåŠŸèƒ½æµ‹è¯•"),
        (run_api_tests, "APIæ¥å£æµ‹è¯•")
    ]

    all_passed = True

    for test_func, test_name in test_functions:
        if not test_func(verbose=verbose, coverage=coverage):
            all_passed = False
            print(f"\nâš ï¸ {test_name}å¤±è´¥ï¼Œç»§ç»­è¿è¡Œå…¶ä»–æµ‹è¯•...")

    return all_passed

def run_slow_tests(verbose: bool = False) -> bool:
    """è¿è¡Œæ…¢é€Ÿæµ‹è¯•"""
    cmd = ["python", "-m", "pytest", "-m", "slow"]

    if verbose:
        cmd.append("-v")

    return run_command(cmd, "æ…¢é€Ÿæµ‹è¯•")

def generate_test_report() -> bool:
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
    print("\nğŸ“Š ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")

    # åˆå¹¶è¦†ç›–ç‡æŠ¥å‘Š
    cmd_merge = [
        "python", "-m", "coverage", "combine",
        "coverage-unit.xml",
        "coverage-integration.xml",
        "coverage-e2e.xml"
    ]

    # ç”ŸæˆHTMLæŠ¥å‘Š
    cmd_html = [
        "python", "-m", "coverage", "html",
        "--directory=htmlcov/combined"
    ]

    # ç”ŸæˆXMLæŠ¥å‘Š
    cmd_xml = [
        "python", "-m", "coverage", "xml",
        "--outfile=coverage-combined.xml"
    ]

    success = True

    if not run_command(cmd_merge, "åˆå¹¶è¦†ç›–ç‡æŠ¥å‘Š"):
        success = False

    if not run_command(cmd_html, "ç”ŸæˆHTMLè¦†ç›–ç‡æŠ¥å‘Š"):
        success = False

    if not run_command(cmd_xml, "ç”ŸæˆXMLè¦†ç›–ç‡æŠ¥å‘Š"):
        success = False

    return success

def check_code_quality() -> bool:
    """æ£€æŸ¥ä»£ç è´¨é‡"""
    print("\nğŸ” æ£€æŸ¥ä»£ç è´¨é‡...")

    quality_checks = [
        (["python", "-m", "flake8", "backend/"], "Flake8ä»£ç é£æ ¼æ£€æŸ¥"),
        (["python", "-m", "black", "--check", "backend/"], "Blackä»£ç æ ¼å¼æ£€æŸ¥"),
        (["python", "-m", "isort", "--check-only", "backend/"], "isortå¯¼å…¥æ’åºæ£€æŸ¥"),
        (["python", "-m", "mypy", "backend/"], "MyPyç±»å‹æ£€æŸ¥"),
        (["python", "-m", "bandit", "-r", "backend/"], "Banditå®‰å…¨æ£€æŸ¥")
    ]

    all_passed = True

    for cmd, check_name in quality_checks:
        try:
            run_command(cmd, check_name)
        except Exception:
            print(f"âš ï¸ {check_name}å‘ç°é—®é¢˜")
            all_passed = False

    return all_passed

def cleanup_test_artifacts() -> bool:
    """æ¸…ç†æµ‹è¯•äº§ç‰©"""
    print("\nğŸ§¹ æ¸…ç†æµ‹è¯•äº§ç‰©...")

    cleanup_commands = [
        (["rm", "-rf", ".pytest_cache"], "æ¸…ç†pytestç¼“å­˜"),
        (["rm", "-rf", "__pycache__"], "æ¸…ç†Pythonç¼“å­˜"),
        (["rm", "-rf", ".coverage"], "æ¸…ç†è¦†ç›–ç‡æ–‡ä»¶"),
        (["rm", "-rf", "htmlcov"], "æ¸…ç†HTMLæŠ¥å‘Š"),
        (["rm", "-rf", "*.xml"], "æ¸…ç†XMLæŠ¥å‘Š"),
        (["find", ".", "-name", "*.pyc", "-delete"], "æ¸…ç†ç¼–è¯‘æ–‡ä»¶"),
        (["find", ".", "-name", "*.pyo", "-delete"], "æ¸…ç†ä¼˜åŒ–æ–‡ä»¶")
    ]

    for cmd, desc in cleanup_commands:
        try:
            subprocess.run(cmd, check=False, capture_output=True)
        except Exception:
            pass  # å¿½ç•¥é”™è¯¯ï¼ŒæŸäº›æ–‡ä»¶å¯èƒ½ä¸å­˜åœ¨

    print("âœ… æµ‹è¯•äº§ç‰©æ¸…ç†å®Œæˆ")
    return True

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ™ºèƒ½æŠ•ç ”é¡¹ç›®æµ‹è¯•è¿è¡Œå™¨")

    parser.add_argument(
        "test_type",
        choices=["unit", "integration", "e2e", "performance", "ai", "api", "all", "slow"],
        help="æµ‹è¯•ç±»å‹"
    )

    parser.add_argument(
        "-v", "--verbose",
        action="store_true",
        help="è¯¦ç»†è¾“å‡º"
    )

    parser.add_argument(
        "--no-coverage",
        action="store_true",
        help="ä¸ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š"
    )

    parser.add_argument(
        "--quality",
        action="store_true",
        help="è¿è¡Œä»£ç è´¨é‡æ£€æŸ¥"
    )

    parser.add_argument(
        "--cleanup",
        action="store_true",
        help="æ¸…ç†æµ‹è¯•äº§ç‰©"
    )

    parser.add_argument(
        "--report",
        action="store_true",
        help="ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"
    )

    args = parser.parse_args()

    # ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•
    os.chdir(Path(__file__).parent.parent)

    success = True

    # æ¸…ç†æ—§äº§ç‰©
    if args.cleanup:
        cleanup_test_artifacts()

    # è¿è¡Œæµ‹è¯•
    if args.test_type == "unit":
        success = run_unit_tests(verbose=args.verbose, coverage=not args.no_coverage)
    elif args.test_type == "integration":
        success = run_integration_tests(verbose=args.verbose)
    elif args.test_type == "e2e":
        success = run_e2e_tests(verbose=args.verbose)
    elif args.test_type == "performance":
        success = run_performance_tests(verbose=args.verbose)
    elif args.test_type == "ai":
        success = run_ai_tests(verbose=args.verbose)
    elif args.test_type == "api":
        success = run_api_tests(verbose=args.verbose)
    elif args.test_type == "all":
        success = run_all_tests(verbose=args.verbose, coverage=not args.no_coverage)
    elif args.test_type == "slow":
        success = run_slow_tests(verbose=args.verbose)

    # ä»£ç è´¨é‡æ£€æŸ¥
    if args.quality and success:
        quality_success = check_code_quality()
        success = success and quality_success

    # ç”ŸæˆæŠ¥å‘Š
    if args.report and success:
        report_success = generate_test_report()
        success = success and report_success

    # è¾“å‡ºç»“æœ
    if success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        sys.exit(0)
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼")
        sys.exit(1)

if __name__ == "__main__":
    main()