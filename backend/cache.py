"""
ç¼“å­˜ç®¡ç†æ¨¡å—

Author: Smart Stock Insider Team
Version: 1.0.0
"""

import json
import pickle
import logging
from typing import Any, Optional, Union, Callable, Dict, List
from datetime import datetime, timedelta
from functools import wraps
import hashlib

import redis.asyncio as redis
from pydantic import BaseModel

from core.config import settings

logger = logging.getLogger(__name__)


class CacheKey:
    """ç¼“å­˜é”®ç”Ÿæˆå™¨"""

    @staticmethod
    def stock_price(symbol: str, date: Optional[str] = None) -> str:
        """ç”Ÿæˆè‚¡ç¥¨ä»·æ ¼ç¼“å­˜é”®"""
        if date:
            return f"stock:price:{symbol}:{date}"
        return f"stock:price:{symbol}:latest"

    @staticmethod
    def stock_indicator(symbol: str, indicator_type: str, period: int) -> str:
        """ç”Ÿæˆè‚¡ç¥¨æŒ‡æ ‡ç¼“å­˜é”®"""
        return f"stock:indicator:{symbol}:{indicator_type}:{period}"

    @staticmethod
    def news_list(category: Optional[str] = None, limit: int = 20) -> str:
        """ç”Ÿæˆæ–°é—»åˆ—è¡¨ç¼“å­˜é”®"""
        if category:
            return f"news:list:{category}:{limit}"
        return f"news:list:default:{limit}"

    @staticmethod
    def news_sentiment(news_id: int, model: str = "default") -> str:
        """ç”Ÿæˆæ–°é—»æƒ…æ„Ÿåˆ†æç¼“å­˜é”®"""
        return f"news:sentiment:{news_id}:{model}"

    @staticmethod
    def ai_analysis(symbol: str, analysis_type: str, model: str = "glm") -> str:
        """ç”ŸæˆAIåˆ†æç¼“å­˜é”®"""
        return f"ai:analysis:{symbol}:{analysis_type}:{model}"

    @staticmethod
    def user_watchlist(user_id: int) -> str:
        """ç”Ÿæˆç”¨æˆ·è‡ªé€‰è‚¡ç¼“å­˜é”®"""
        return f"user:watchlist:{user_id}"

    @staticmethod
    def search_results(query: str, result_type: str = "stock") -> str:
        """ç”Ÿæˆæœç´¢ç»“æœç¼“å­˜é”®"""
        # å¯¹æŸ¥è¯¢è¿›è¡Œå“ˆå¸Œä»¥é¿å…ç‰¹æ®Šå­—ç¬¦é—®é¢˜
        query_hash = hashlib.md5(query.encode()).hexdigest()[:8]
        return f"search:{result_type}:{query_hash}"

    @staticmethod
    def api_rate_limit(client_id: str, endpoint: str) -> str:
        """ç”ŸæˆAPIé™æµç¼“å­˜é”®"""
        now = datetime.now().strftime("%Y%m%d%H")
        return f"rate_limit:{client_id}:{endpoint}:{now}"

    @staticmethod
    def service_health(service_name: str) -> str:
        """ç”ŸæˆæœåŠ¡å¥åº·çŠ¶æ€ç¼“å­˜é”®"""
        return f"service:health:{service_name}"

    @staticmethod
    def backtest_result(strategy_id: str, symbol: str) -> str:
        """ç”Ÿæˆå›æµ‹ç»“æœç¼“å­˜é”®"""
        return f"backtest:result:{strategy_id}:{symbol}"


class CacheSerializer:
    """ç¼“å­˜åºåˆ—åŒ–å™¨"""

    @staticmethod
    def serialize(data: Any) -> bytes:
        """åºåˆ—åŒ–æ•°æ®"""
        try:
            # å°è¯•JSONåºåˆ—åŒ–ï¼ˆæ›´å¿«ï¼Œæ›´æ˜“è¯»ï¼‰
            if isinstance(data, (dict, list, str, int, float, bool)) or data is None:
                return json.dumps(data, ensure_ascii=False, default=str).encode('utf-8')
            else:
                # å¤æ‚å¯¹è±¡ä½¿ç”¨pickle
                return pickle.dumps(data)
        except Exception as e:
            logger.error(f"ç¼“å­˜åºåˆ—åŒ–å¤±è´¥: {e}")
            raise

    @staticmethod
    def deserialize(data: bytes, use_pickle: bool = False) -> Any:
        """ååºåˆ—åŒ–æ•°æ®"""
        try:
            if use_pickle:
                return pickle.loads(data)
            else:
                # å°è¯•JSONååºåˆ—åŒ–
                return json.loads(data.decode('utf-8'))
        except (json.JSONDecodeError, pickle.PickleError) as e:
            logger.error(f"ç¼“å­˜ååºåˆ—åŒ–å¤±è´¥: {e}")
            raise


class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨"""

    def __init__(self):
        self.redis_client: Optional[redis.Redis] = None
        self.default_ttl = settings.CACHE_TTL_DEFAULT
        self.key_prefix = "smart_stock:"

    async def initialize(self):
        """åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨"""
        try:
            self.redis_client = redis.from_url(
                settings.REDIS_URL,
                encoding="utf-8",
                decode_responses=False,  # ä½¿ç”¨bytesä»¥æ”¯æŒåºåˆ—åŒ–
                socket_connect_timeout=5,
                socket_timeout=5,
                retry_on_timeout=True,
                health_check_interval=30
            )
            await self.redis_client.ping()
            logger.info("âœ… ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            # ç¼“å­˜å¤±è´¥ä¸åº”è¯¥é˜»æ­¢åº”ç”¨å¯åŠ¨
            self.redis_client = None

    def _make_key(self, key: str) -> str:
        """ç”Ÿæˆå®Œæ•´çš„ç¼“å­˜é”®"""
        return f"{self.key_prefix}{key}"

    async def get(
        self,
        key: str,
        default: Any = None,
        use_pickle: bool = False
    ) -> Any:
        """
        è·å–ç¼“å­˜å€¼

        Args:
            key: ç¼“å­˜é”®
            default: é»˜è®¤å€¼
            use_pickle: æ˜¯å¦ä½¿ç”¨pickleåºåˆ—åŒ–

        Returns:
            ç¼“å­˜å€¼æˆ–é»˜è®¤å€¼
        """
        if not self.redis_client:
            return default

        try:
            full_key = self._make_key(key)
            data = await self.redis_client.get(full_key)

            if data is None:
                return default

            return CacheSerializer.deserialize(data, use_pickle)

        except Exception as e:
            logger.error(f"è·å–ç¼“å­˜å¤±è´¥ {key}: {e}")
            return default

    async def set(
        self,
        key: str,
        value: Any,
        ttl: Optional[int] = None,
        use_pickle: bool = False
    ) -> bool:
        """
        è®¾ç½®ç¼“å­˜å€¼

        Args:
            key: ç¼“å­˜é”®
            value: ç¼“å­˜å€¼
            ttl: è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
            use_pickle: æ˜¯å¦ä½¿ç”¨pickleåºåˆ—åŒ–

        Returns:
            è®¾ç½®æ˜¯å¦æˆåŠŸ
        """
        if not self.redis_client:
            return False

        try:
            full_key = self._make_key(key)
            data = CacheSerializer.serialize(value)
            expire_time = ttl or self.default_ttl

            await self.redis_client.setex(full_key, expire_time, data)
            logger.debug(f"ç¼“å­˜è®¾ç½®æˆåŠŸ: {key} (TTL: {expire_time}s)")
            return True

        except Exception as e:
            logger.error(f"è®¾ç½®ç¼“å­˜å¤±è´¥ {key}: {e}")
            return False

    async def delete(self, key: str) -> bool:
        """
        åˆ é™¤ç¼“å­˜

        Args:
            key: ç¼“å­˜é”®

        Returns:
            åˆ é™¤æ˜¯å¦æˆåŠŸ
        """
        if not self.redis_client:
            return False

        try:
            full_key = self._make_key(key)
            result = await self.redis_client.delete(full_key)
            logger.debug(f"ç¼“å­˜åˆ é™¤: {key} - {'æˆåŠŸ' if result else 'ä¸å­˜åœ¨'}")
            return result > 0

        except Exception as e:
            logger.error(f"åˆ é™¤ç¼“å­˜å¤±è´¥ {key}: {e}")
            return False

    async def exists(self, key: str) -> bool:
        """
        æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨

        Args:
            key: ç¼“å­˜é”®

        Returns:
            ç¼“å­˜æ˜¯å¦å­˜åœ¨
        """
        if not self.redis_client:
            return False

        try:
            full_key = self._make_key(key)
            result = await self.redis_client.exists(full_key)
            return result > 0

        except Exception as e:
            logger.error(f"æ£€æŸ¥ç¼“å­˜å­˜åœ¨æ€§å¤±è´¥ {key}: {e}")
            return False

    async def expire(self, key: str, ttl: int) -> bool:
        """
        è®¾ç½®ç¼“å­˜è¿‡æœŸæ—¶é—´

        Args:
            key: ç¼“å­˜é”®
            ttl: è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            è®¾ç½®æ˜¯å¦æˆåŠŸ
        """
        if not self.redis_client:
            return False

        try:
            full_key = self._make_key(key)
            result = await self.redis_client.expire(full_key, ttl)
            return result

        except Exception as e:
            logger.error(f"è®¾ç½®ç¼“å­˜è¿‡æœŸæ—¶é—´å¤±è´¥ {key}: {e}")
            return False

    async def ttl(self, key: str) -> int:
        """
        è·å–ç¼“å­˜å‰©ä½™æ—¶é—´

        Args:
            key: ç¼“å­˜é”®

        Returns:
            å‰©ä½™æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œ-1è¡¨ç¤ºæ°¸ä¸è¿‡æœŸï¼Œ-2è¡¨ç¤ºä¸å­˜åœ¨
        """
        if not self.redis_client:
            return -2

        try:
            full_key = self._make_key(key)
            return await self.redis_client.ttl(full_key)

        except Exception as e:
            logger.error(f"è·å–ç¼“å­˜TTLå¤±è´¥ {key}: {e}")
            return -2

    async def increment(self, key: str, amount: int = 1) -> Optional[int]:
        """
        é€’å¢ç¼“å­˜å€¼

        Args:
            key: ç¼“å­˜é”®
            amount: é€’å¢æ•°é‡

        Returns:
            é€’å¢åçš„å€¼
        """
        if not self.redis_client:
            return None

        try:
            full_key = self._make_key(key)
            return await self.redis_client.incrby(full_key, amount)

        except Exception as e:
            logger.error(f"é€’å¢ç¼“å­˜å¤±è´¥ {key}: {e}")
            return None

    async def get_many(self, keys: List[str], use_pickle: bool = False) -> Dict[str, Any]:
        """
        æ‰¹é‡è·å–ç¼“å­˜

        Args:
            keys: ç¼“å­˜é”®åˆ—è¡¨
            use_pickle: æ˜¯å¦ä½¿ç”¨pickleåºåˆ—åŒ–

        Returns:
            ç¼“å­˜å€¼å­—å…¸
        """
        if not self.redis_client or not keys:
            return {}

        try:
            full_keys = [self._make_key(key) for key in keys]
            values = await self.redis_client.mget(full_keys)

            result = {}
            for key, value in zip(keys, values):
                if value is not None:
                    try:
                        result[key] = CacheSerializer.deserialize(value, use_pickle)
                    except Exception as e:
                        logger.error(f"ååºåˆ—åŒ–ç¼“å­˜å¤±è´¥ {key}: {e}")
                        result[key] = None
                else:
                    result[key] = None

            return result

        except Exception as e:
            logger.error(f"æ‰¹é‡è·å–ç¼“å­˜å¤±è´¥: {e}")
            return {}

    async def set_many(
        self,
        mapping: Dict[str, Any],
        ttl: Optional[int] = None,
        use_pickle: bool = False
    ) -> bool:
        """
        æ‰¹é‡è®¾ç½®ç¼“å­˜

        Args:
            mapping: é”®å€¼å¯¹æ˜ å°„
            ttl: è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
            use_pickle: æ˜¯å¦ä½¿ç”¨pickleåºåˆ—åŒ–

        Returns:
            è®¾ç½®æ˜¯å¦æˆåŠŸ
        """
        if not self.redis_client or not mapping:
            return False

        try:
            expire_time = ttl or self.default_ttl
            pipe = self.redis_client.pipeline()

            for key, value in mapping.items():
                full_key = self._make_key(key)
                data = CacheSerializer.serialize(value, use_pickle)
                pipe.setex(full_key, expire_time, data)

            await pipe.execute()
            logger.debug(f"æ‰¹é‡è®¾ç½®ç¼“å­˜æˆåŠŸ: {len(mapping)} ä¸ªé”®")
            return True

        except Exception as e:
            logger.error(f"æ‰¹é‡è®¾ç½®ç¼“å­˜å¤±è´¥: {e}")
            return False

    async def clear_pattern(self, pattern: str) -> int:
        """
        æ¸…é™¤åŒ¹é…æ¨¡å¼çš„ç¼“å­˜

        Args:
            pattern: åŒ¹é…æ¨¡å¼

        Returns:
            æ¸…é™¤çš„é”®æ•°é‡
        """
        if not self.redis_client:
            return 0

        try:
            full_pattern = self._make_key(pattern)
            keys = await self.redis_client.keys(full_pattern)

            if keys:
                count = await self.redis_client.delete(*keys)
                logger.info(f"æ¸…é™¤ç¼“å­˜æ¨¡å¼ {pattern}: {count} ä¸ªé”®")
                return count

            return 0

        except Exception as e:
            logger.error(f"æ¸…é™¤ç¼“å­˜æ¨¡å¼å¤±è´¥ {pattern}: {e}")
            return 0

    async def get_stats(self) -> Dict[str, Any]:
        """
        è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        if not self.redis_client:
            return {"status": "disconnected"}

        try:
            info = await self.redis_client.info()
            return {
                "status": "connected",
                "used_memory": info.get("used_memory_human"),
                "connected_clients": info.get("connected_clients"),
                "total_commands_processed": info.get("total_commands_processed"),
                "keyspace_hits": info.get("keyspace_hits", 0),
                "keyspace_misses": info.get("keyspace_misses", 0),
                "hit_rate": (
                    info.get("keyspace_hits", 0) / max(
                        info.get("keyspace_hits", 0) + info.get("keyspace_misses", 0), 1
                    )
                )
            }

        except Exception as e:
            logger.error(f"è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {e}")
            return {"status": "error", "error": str(e)}

    async def close(self):
        """å…³é—­ç¼“å­˜è¿æ¥"""
        if self.redis_client:
            await self.redis_client.close()
            logger.info("ğŸ”š ç¼“å­˜è¿æ¥å·²å…³é—­")


# å…¨å±€ç¼“å­˜ç®¡ç†å™¨å®ä¾‹
cache_manager = CacheManager()


def cached(
    key_func: Callable,
    ttl: Optional[int] = None,
    use_pickle: bool = False,
    cache_none: bool = False
):
    """
    ç¼“å­˜è£…é¥°å™¨

    Args:
        key_func: ç”Ÿæˆç¼“å­˜é”®çš„å‡½æ•°
        ttl: è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
        use_pickle: æ˜¯å¦ä½¿ç”¨pickleåºåˆ—åŒ–
        cache_none: æ˜¯å¦ç¼“å­˜Noneå€¼
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def async_wrapper(*args, **kwargs):
            cache_key = key_func(*args, **kwargs)

            # å°è¯•ä»ç¼“å­˜è·å–
            cached_result = await cache_manager.get(cache_key, use_pickle=use_pickle)
            if cached_result is not None or (cached_result is None and cache_none):
                logger.debug(f"ç¼“å­˜å‘½ä¸­: {cache_key}")
                return cached_result

            # æ‰§è¡Œå‡½æ•°
            logger.debug(f"ç¼“å­˜æœªå‘½ä¸­: {cache_key}")
            result = await func(*args, **kwargs)

            # ç¼“å­˜ç»“æœ
            if result is not None or cache_none:
                await cache_manager.set(cache_key, result, ttl, use_pickle)

            return result

        @wraps(func)
        def sync_wrapper(*args, **kwargs):
            cache_key = key_func(*args, **kwargs)

            # åŒæ­¥å‡½æ•°çš„ç¼“å­˜é€»è¾‘ï¼ˆç®€åŒ–ç‰ˆï¼‰
            # æ³¨æ„ï¼šè¿™é‡Œç®€åŒ–äº†åŒæ­¥å¤„ç†ï¼Œå®é™…é¡¹ç›®ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„å¤„ç†
            return func(*args, **kwargs)

        return async_wrapper if hasattr(func, '__await__') else sync_wrapper

    return decorator


# é¢„å®šä¹‰çš„ç¼“å­˜é…ç½®
CACHE_CONFIGS = {
    "stock_price": {"ttl": settings.CACHE_TTL_STOCK_DATA, "use_pickle": False},
    "stock_indicator": {"ttl": 3600, "use_pickle": False},  # 1å°æ—¶
    "news_list": {"ttl": settings.CACHE_TTL_NEWS, "use_pickle": False},
    "news_sentiment": {"ttl": 7200, "use_pickle": False},  # 2å°æ—¶
    "ai_analysis": {"ttl": 1800, "use_pickle": False},  # 30åˆ†é’Ÿ
    "search_results": {"ttl": 600, "use_pickle": False},  # 10åˆ†é’Ÿ
    "user_watchlist": {"ttl": 300, "use_pickle": False},  # 5åˆ†é’Ÿ
    "backtest_result": {"ttl": 3600, "use_pickle": True},  # 1å°æ—¶ï¼Œå¤æ‚å¯¹è±¡
}